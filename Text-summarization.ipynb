{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13338,
     "status": "ok",
     "timestamp": 1573938335046,
     "user": {
      "displayName": "Amit Makashir",
      "photoUrl": "",
      "userId": "15687688426475542440"
     },
     "user_tz": 300
    },
    "id": "qkGVCngN3x1x",
    "outputId": "b599824e-cb7c-4836-8023-61afd672bc27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textsearch\n",
      "  Downloading https://files.pythonhosted.org/packages/42/a8/03407021f9555043de5492a2bd7a35c56cc03c2510092b5ec018cae1bbf1/textsearch-0.0.17-py2.py3-none-any.whl\n",
      "Collecting pyahocorasick (from textsearch)\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/9f/f0d8e8850e12829eea2e778f1c90e3c53a9a799b7f412082a5d21cd19ae1/pyahocorasick-1.4.0.tar.gz (312kB)\n",
      "Collecting Unidecode (from textsearch)\n",
      "  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
      "Building wheels for collected packages: pyahocorasick\n",
      "  Building wheel for pyahocorasick (setup.py): started\n",
      "  Building wheel for pyahocorasick (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\GELab\\AppData\\Local\\pip\\Cache\\wheels\\0a\\90\\61\\87a55f5b459792fbb2b7ba6b31721b06ff5cf6bde541b40994\n",
      "Successfully built pyahocorasick\n",
      "Installing collected packages: pyahocorasick, Unidecode, textsearch\n",
      "Successfully installed Unidecode-1.1.1 pyahocorasick-1.4.0 textsearch-0.0.17\n",
      "Collecting contractions\n",
      "  Downloading https://files.pythonhosted.org/packages/5a/6a/7bde208d21b4f7db1b666739dca8826d8fd7af34a14fddfda9b597ab8a45/contractions-0.0.23-py2.py3-none-any.whl\n",
      "Requirement already satisfied: textsearch in c:\\users\\gelab\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from contractions) (0.0.17)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\gelab\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from textsearch->contractions) (1.4.0)\n",
      "Requirement already satisfied: Unidecode in c:\\users\\gelab\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from textsearch->contractions) (1.1.1)\n",
      "Installing collected packages: contractions\n",
      "Successfully installed contractions-0.0.23\n"
     ]
    }
   ],
   "source": [
    "# !pip uninstall tensorflow\n",
    "# !pip install --upgrade tensorflow\n",
    "!pip install textsearch\n",
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13291,
     "status": "ok",
     "timestamp": 1573938335048,
     "user": {
      "displayName": "Amit Makashir",
      "photoUrl": "",
      "userId": "15687688426475542440"
     },
     "user_tz": 300
    },
    "id": "cxE8LwHl2Sri",
    "outputId": "e6f05b3e-a2bf-4999-92f1-8ded754ae866"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13270,
     "status": "ok",
     "timestamp": 1573938335050,
     "user": {
      "displayName": "Amit Makashir",
      "photoUrl": "",
      "userId": "15687688426475542440"
     },
     "user_tz": 300
    },
    "id": "r3mwQ0Bzyz7_",
    "outputId": "587025c6-e297-40ff-8e02-411603f9fbfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'drive/My Drive/ANLP-Project/'\n",
      "/content/drive/My Drive/ANLP-Project\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/content/drive/My Drive/ANLP-Project'"
      ]
     },
     "execution_count": 164,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Project Path\n",
    "%pwd\n",
    "%cd drive/My Drive/ANLP-Project/\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13222,
     "status": "ok",
     "timestamp": 1573938335051,
     "user": {
      "displayName": "Amit Makashir",
      "photoUrl": "",
      "userId": "15687688426475542440"
     },
     "user_tz": 300
    },
    "id": "7NOHp85ivHSQ",
    "outputId": "f7d35d72-fb7a-4102-a56b-46592021a3cd"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'contractions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-839ae6d5543e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcontractions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"display.max_colwidth\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'contractions'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "import contractions\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "from Data.attention import AttentionLayer\n",
    "# Downloads\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SfDX0nhyyUSD"
   },
   "outputs": [],
   "source": [
    "assert(tf.__version__ == \"2.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dkp3jbM60D7h"
   },
   "outputs": [],
   "source": [
    "data_directory_path = \"Data/\"\n",
    "reviews_data = data_directory_path + \"Reviews.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vvGD6hRH02MQ"
   },
   "outputs": [],
   "source": [
    "reviews_df = pd.read_csv(reviews_data,nrows=1000)\n",
    "# reviews_df = pd.read_csv(reviews_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13411,
     "status": "ok",
     "timestamp": 1573938335320,
     "user": {
      "displayName": "Amit Makashir",
      "photoUrl": "",
      "userId": "15687688426475542440"
     },
     "user_tz": 300
    },
    "id": "YnlDi_CIN-QA",
    "outputId": "f77a355c-e8e0-4431-dd64-492903f76346"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Summary                                                                                                                                                                                                     Text\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...\n",
       "1      Not as Advertised           Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".\n",
       "2  \"Delight\" says it all  This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...\n",
       "3         Cough Medicine  If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The fl...\n",
       "4            Great taffy                                                             Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal."
      ]
     },
     "execution_count": 169,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = reviews_df.filter(items=[\"Summary\",\"Text\"])\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B1ACjJRU194O"
   },
   "outputs": [],
   "source": [
    "data_df.drop_duplicates(subset=['Text'],inplace=True)#dropping duplicates\n",
    "data_df.dropna(axis=0,inplace=True)#dropping na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13388,
     "status": "ok",
     "timestamp": 1573938335324,
     "user": {
      "displayName": "Amit Makashir",
      "photoUrl": "",
      "userId": "15687688426475542440"
     },
     "user_tz": 300
    },
    "id": "OECEF2OA1uwa",
    "outputId": "20cd7374-bdcb-40fc-ed43-8620d372f8f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 997 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      "Summary    997 non-null object\n",
      "Text       997 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 23.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qTm3uOvK4k0_"
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13361,
     "status": "ok",
     "timestamp": 1573938335328,
     "user": {
      "displayName": "Amit Makashir",
      "photoUrl": "",
      "userId": "15687688426475542440"
     },
     "user_tz": 300
    },
    "id": "ZjxJ3SU76Kl6",
    "outputId": "7079da8d-6bed-4d50-b3c4-cdf3dd486ae6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you all looking secret ingredient robitussin believe found . got addition root beer extract ordered ( good ) made cherry soda .'"
      ]
     },
     "execution_count": 173,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text_string, remove_stop_words=False):\n",
    "    text_string = text_string.lower()\n",
    "    tokenized_words = word_tokenize(text_string)\n",
    "\n",
    "    # Remove stop words\n",
    "    if remove_stop_words:\n",
    "        tokenized_words = [word for word in tokenized_words if word not in stop_words]\n",
    "    \n",
    "    tokenized_words_str = \" \".join(tokenized_words)\n",
    "    \n",
    "    tokenized_words_str = contractions.fix(tokenized_words_str)\n",
    "    return tokenized_words_str\n",
    "\n",
    "\n",
    "s = \"If y'all are looking for the secret ingredient in Robitussin I believe I have found it. I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.\"\n",
    "clean_text(s,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gwY8_ZDN6kwL"
   },
   "outputs": [],
   "source": [
    "data_df[\"Text\"] = data_df[\"Text\"].apply(lambda x: clean_text(x))\n",
    "data_df[\"Summary\"] = data_df[\"Summary\"].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14682,
     "status": "ok",
     "timestamp": 1573938336679,
     "user": {
      "displayName": "Amit Makashir",
      "photoUrl": "",
      "userId": "15687688426475542440"
     },
     "user_tz": 300
    },
    "id": "qW7afCA9JDRj",
    "outputId": "5dc2ba29-84ed-482b-87ac-148f8333579d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df[\"Text_len\"] = data_df[\"Text\"].apply(lambda x: len(x.split(\" \")))\n",
    "data_df[\"Text_len\"].hist(bins=30)\n",
    "\n",
    "max_text_len = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14669,
     "status": "ok",
     "timestamp": 1573938336681,
     "user": {
      "displayName": "Amit Makashir",
      "photoUrl": "",
      "userId": "15687688426475542440"
     },
     "user_tz": 300
    },
    "id": "azFJ82QTK4jn",
    "outputId": "861762be-64c6-475d-81b9-b21b09792575"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwiVlBQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df[\"Summary_len\"] = data_df[\"Summary\"].apply(lambda x: len(x.split(\" \")))\n",
    "data_df[\"Summary_len\"].hist(bins=30)\n",
    "max_summary_len = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NTHof4MXPrsn"
   },
   "source": [
    "From the above Histograms, we have chosen maxlen for Text as 200 and Summary as 10\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14656,
     "status": "ok",
     "timestamp": 1573938336683,
     "user": {
      "displayName": "Amit Makashir",
      "photoUrl": "",
      "userId": "15687688426475542440"
     },
     "user_tz": 300
    },
    "id": "T2Ooc-7NM0Hw",
    "outputId": "b74a6012-ab48-42b5-b3da-e8c23f196fe0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(997, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(981, 4)"
      ]
     },
     "execution_count": 177,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data_df.shape)\n",
    "data_df = data_df[(data_df[\"Summary_len\"] <= max_summary_len) & (data_df[\"Text_len\"] <= max_text_len)]\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "10DBZ1gNQHYt"
   },
   "outputs": [],
   "source": [
    "data_df['Summary'] = data_df['Summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "omdzfTPuRs8c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f8xZc4PlR0GF"
   },
   "outputs": [],
   "source": [
    "xTrain,xValid,yTrain,yValid=train_test_split(np.array(data_df['Text']),np.array(data_df['Summary']),test_size=0.2,random_state=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nHYHp8cESefp"
   },
   "source": [
    "tokenising and converting words in sentence as integer sequences\n",
    "say the sentence 'hello world' is converted to [[0,1],[1,0]] given there are in total 2 distinct words in the entire corpus.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0b0bbgx2WQiQ"
   },
   "outputs": [],
   "source": [
    "def getNumVocabWordsToBeKept(minReqFreqencyOfWords,tokenizer):\n",
    "\n",
    "    numRareWords=0\n",
    "    totalUniqueWords=0\n",
    "    totalFreqWords = 0\n",
    "    totalFreqOfRareWords = 0\n",
    "\n",
    "    for word,freq in tokenizer.word_counts.items():\n",
    "        totalUniqueWords += 1\n",
    "        totalFreqWords += freq\n",
    "        if(freq<minReqFreqencyOfWords):\n",
    "            numRareWords += 1\n",
    "            totalFreqOfRareWords+=freq\n",
    "\n",
    "    print(\"% of rare words in vocabulary:\",(numRareWords/totalUniqueWords)*100)\n",
    "    print(\"Total Coverage of rare words:\",(totalFreqOfRareWords/totalFreqWords)*100)\n",
    "\n",
    "    return totalUniqueWords - numRareWords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14837,
     "status": "ok",
     "timestamp": 1573938336932,
     "user": {
      "displayName": "Amit Makashir",
      "photoUrl": "",
      "userId": "15687688426475542440"
     },
     "user_tz": 300
    },
    "id": "2nbU3aGJSX-O",
    "outputId": "871cac0b-b48d-4808-f1ec-d6dcf6bb4f2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 71.44255235858289\n",
      "Total Coverage of rare words: 9.280343335461446\n"
     ]
    }
   ],
   "source": [
    "## getting frequency for X\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(xTrain))\n",
    "\n",
    "numReqXWords = getNumVocabWordsToBeKept(4,x_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YRTuGgFwez53"
   },
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer(num_words=numReqXWords) \n",
    "x_tokenizer.fit_on_texts(list(xTrain))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "xTrain_seq    =   x_tokenizer.texts_to_sequences(xTrain) \n",
    "xValid_seq   =   x_tokenizer.texts_to_sequences(xValid)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "xTrain    =   pad_sequences(xTrain_seq,  maxlen=max_text_len, padding='post')\n",
    "xValid   =   pad_sequences(xValid_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "xVocab   =  x_tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15367,
     "status": "ok",
     "timestamp": 1573938337497,
     "user": {
      "displayName": "Amit Makashir",
      "photoUrl": "",
      "userId": "15687688426475542440"
     },
     "user_tz": 300
    },
    "id": "EH76cqX0cCQu",
    "outputId": "c4f20578-48cb-493a-da30-64cf8b3c42c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 61.44329896907217\n",
      "Total Coverage of rare words: 12.5\n"
     ]
    }
   ],
   "source": [
    "## getting frequency for Y\n",
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(yTrain))\n",
    "numReqYWords = getNumVocabWordsToBeKept(2,y_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AvIW3OkWci3n"
   },
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer(num_words=numReqYWords) \n",
    "y_tokenizer.fit_on_texts(list(yTrain))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "yTrain_seq    =   y_tokenizer.texts_to_sequences(yTrain) \n",
    "yValid_seq   =   y_tokenizer.texts_to_sequences(yValid) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "yTrain    =   pad_sequences(yTrain_seq, maxlen=max_summary_len, padding='post')\n",
    "yValid   =   pad_sequences(yValid_seq, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "#size of vocabulary\n",
    "yVocab  =   y_tokenizer.num_words +1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TB9oMqpUjmV2"
   },
   "source": [
    "\n",
    "##### deleting the rows that contain only START and END tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RXov1TSwjGe-"
   },
   "outputs": [],
   "source": [
    "\n",
    "def removeRowsWithOnlyStartEnd(textSet,summarySet):\n",
    "    \"\"\"\n",
    "    startEnd tokens are only in summarySet\n",
    "    \"\"\"\n",
    "    ind=[]\n",
    "    for i in range(len(summarySet)):\n",
    "        cnt=0\n",
    "        for j in summarySet[i]:\n",
    "            if j!=0:\n",
    "                cnt=cnt+1\n",
    "        if(cnt==2):\n",
    "            ind.append(i)\n",
    "\n",
    "    summarySet=np.delete(summarySet,ind, axis=0)\n",
    "    textSet=np.delete(textSet,ind, axis=0)\n",
    "    return textSet,summarySet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WZV-l7Ttkn1i"
   },
   "outputs": [],
   "source": [
    "xTrain,yTrain = removeRowsWithOnlyStartEnd(xTrain,yTrain)\n",
    "xValid,yValid = removeRowsWithOnlyStartEnd(xValid,yValid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15301,
     "status": "ok",
     "timestamp": 1573938337507,
     "user": {
      "displayName": "Amit Makashir",
      "photoUrl": "",
      "userId": "15687688426475542440"
     },
     "user_tz": 300
    },
    "id": "xfz3N7Bzmh7Z",
    "outputId": "58fb6982-e220-4fb7-f08a-a9fe0f78fad8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "970"
      ]
     },
     "execution_count": 187,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_tokenizer.index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15282,
     "status": "ok",
     "timestamp": 1573938337509,
     "user": {
      "displayName": "Amit Makashir",
      "photoUrl": "",
      "userId": "15687688426475542440"
     },
     "user_tz": 300
    },
    "id": "5-TUw6q3muJk",
    "outputId": "f2bd868d-7192-465b-844a-00b7472d0b11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5109"
      ]
     },
     "execution_count": 188,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_tokenizer.index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18297,
     "status": "ok",
     "timestamp": 1573938340553,
     "user": {
      "displayName": "Amit Makashir",
      "photoUrl": "",
      "userId": "15687688426475542440"
     },
     "user_tz": 300
    },
    "id": "reecvrgEm-_X",
    "outputId": "c2f1f54e-bd9b-400f-d3ba-733418ba53e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 400)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 400, 100)     146000      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 400, 300), ( 481200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 400, 300), ( 721200      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    37500       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 400, 300), ( 721200      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 300),  481200      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 600)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 375)    225375      concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 2,993,975\n",
      "Trainable params: 2,993,975\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "latent_dim = 300\n",
    "embedding_dim=100\n",
    "\n",
    "########################### Encoder  #####################################\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "\n",
    "#embedding layer\n",
    "enc_emb =  Embedding(xVocab, embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "#encoder lstm 1\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "#encoder lstm 2\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#encoder lstm 3\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "\n",
    "\n",
    "################################ decoder #############\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,)) ## target vector except the last token\n",
    "\n",
    "#embedding layer\n",
    "dec_emb_layer = Embedding(yVocab, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "# Attention layer\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# Concat attention input and decoder LSTM output\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#dense layer\n",
    "decoder_dense =  TimeDistributed(Dense(yVocab, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "#Define the model \n",
    "FullModel = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "FullModel.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8YYQO6K_r9Gw"
   },
   "outputs": [],
   "source": [
    "FullModel.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Me85g3Hv6zA"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 877870,
     "status": "error",
     "timestamp": 1573939200206,
     "user": {
      "displayName": "Amit Makashir",
      "photoUrl": "",
      "userId": "15687688426475542440"
     },
     "user_tz": 300
    },
    "id": "tjL5fi-7wGRq",
    "outputId": "9c2783c8-24e8-4a34-b144-ec6215bd77ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 749 samples, validate on 180 samples\n",
      "Epoch 1/10\n",
      "749/749 [==============================] - 201s 268ms/sample - loss: 3.6978 - val_loss: 1.5649\n",
      "Epoch 2/10\n",
      "749/749 [==============================] - 192s 256ms/sample - loss: 1.7476 - val_loss: 1.4964\n",
      "Epoch 3/10\n",
      "749/749 [==============================] - 189s 252ms/sample - loss: 1.7169 - val_loss: 1.4420\n",
      "Epoch 4/10\n",
      "749/749 [==============================] - 189s 252ms/sample - loss: 1.6786 - val_loss: 1.4161\n",
      "Epoch 5/10\n",
      "384/749 [==============>...............] - ETA: 1:24 - loss: 1.5950WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-abca2aae6733>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                   \u001b[0myTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                   validation_data=([xValid,yValid[:,:-1]], yValid.reshape(yValid.shape[0],yValid.shape[1], 1)[:,1:]))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history=FullModel.fit([xTrain,yTrain[:,:-1]], \n",
    "                  yTrain.reshape(yTrain.shape[0],yTrain.shape[1], 1)[:,1:] ,\n",
    "                  epochs=10,callbacks=[es],batch_size=128, \n",
    "                  validation_data=([xValid,yValid[:,:-1]], yValid.reshape(yValid.shape[0],yValid.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4WQxxlbNTG0V"
   },
   "outputs": [],
   "source": [
    "reverse_target_word_index=y_tokenizer.index_word\n",
    "reverse_source_word_index=x_tokenizer.index_word\n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BPIOX7MCXE11"
   },
   "source": [
    "## Inference\n",
    "Set up the inference for the encoder and decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cFzFL1xHyjO1"
   },
   "outputs": [],
   "source": [
    "## encoder only model so as to get the encoder outputs\n",
    "encoder_model_inf = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "## after the encoder outputs,\n",
    "decoder_state_input_h = Input(shape=(latent_dim,)) ## hidden state to be initialised , basically the last output of sequence\n",
    "decoder_state_input_c = Input(shape=(latent_dim,)) ## cell state\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim)) ## all sequences required for attention \n",
    "dec_emb_inf = dec_emb_layer(decoder_inputs) ## getting the embedings in the summary\n",
    "\n",
    "## extract decoder outputs for each word\n",
    "decoder_outputs_inf, state_h_inf, state_c_inf = decoder_lstm(dec_emb_inf, initial_state=[decoder_state_input_h, decoder_state_input_c]) \n",
    "\n",
    "## send the decoder output (1,latentDim) and encoder outputs (maxTextLen, latentDim) into attention layer to get final decoder output\n",
    "\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs_inf])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs_inf, attn_out_inf])\n",
    "decoder_outputs_inf = decoder_dense(decoder_inf_concat) ## time distributed\n",
    "\n",
    "# Final decoder model for inference\n",
    "## decoder_inputs : target vector without last token, in this case a single word\n",
    "decoder_model_inf = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs_inf] + [state_h_inf, state_c_inf])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ak7NBp4tidBM"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model_inf.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index['sostok']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "      \n",
    "        output_tokens, new_h, new_c = decoder_model_inf.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :]) ## need to change this to beam search\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index+1]\n",
    "\n",
    "        \n",
    "        \n",
    "        if(sampled_token!='eostok'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = new_h, new_c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MA83JDXXjaFK"
   },
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
    "            newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2328,
     "status": "ok",
     "timestamp": 1573942521683,
     "user": {
      "displayName": "Amit Makashir",
      "photoUrl": "",
      "userId": "15687688426475542440"
     },
     "user_tz": 300
    },
    "id": "_5wf7Z3gjhmq",
    "outputId": "71ccf2f8-5c41-4223-b8b7-c0099e313520"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: these are the best tasting tuna pack they make in my opinion make a great on the go snack and really satisfying with the tomato \n",
      "Original summary: tasty \n",
      "Predicted summary:  the great great great sostok sostok sostok sostok sostok sostok sostok sostok sostok sostok\n",
      "\n",
      "\n",
      "Review: what a deal this is the salt you can use this box should last our family the year no problem sea salt will not your blood as regular salt will \n",
      "Original summary: great deal \n",
      "Predicted summary:  the great great great sostok sostok sostok sostok sostok sostok sostok sostok sostok sostok\n",
      "\n",
      "\n",
      "Review: mccann 's makes oatmeal for every oatmeal one likes it from the raw state that cooks for half an hour to the instant which can be done in the for under three minutes it 's all good that 's for sure and the of the instant variety is that it is available in different flavors as well as regular br this variety pack different tastes to be as well as giving you a to experience the difference between mccann 's and other well known what i personally like about mccann 's is that it cooks up thicker and with more body than the top brand here in the apples cinnamon though to be a little so you may want to with the amount of water you add in my the oatmeal cooks up in about one minute and seconds so you should also watch that to get a on how much time and water to use br the only bad thing if you can it a bad thing about this is that you have to buy in lot so you will end up with six ten count boxes this is good if you have a whole family of oatmeal eaters but if you are a single person well love oatmeal \n",
      "Original summary: oatmeal for oatmeal lovers \n",
      "Predicted summary:  the great great great sostok sostok sostok sostok sostok sostok sostok sostok sostok sostok\n",
      "\n",
      "\n",
      "Review: try this you might like it i did and i am quite addicted it is too easy to prepare it tastes great and it the flavors you cook it with the price is really good and well worth the purchase if you like this type of couscous like i do then give this one a try it can be eaten hot room or in a cold salad with a variety of and other flavors it takes on the other flavors very well when mixed i cooked the couscous with a broth and oil for added flavor and it my taste big time i will be back for more \n",
      "Original summary: one of my foods \n",
      "Predicted summary:  the great great great sostok sostok sostok sostok sostok sostok sostok sostok sostok sostok\n",
      "\n",
      "\n",
      "Review: my 7 year old cocker spaniel loves this food and it 's good for him he needs to lose a few pounds and this is doing the trick glad i found it on amazon hard to find elsewhere \n",
      "Original summary: happy dog \n",
      "Predicted summary:  the great great great sostok sostok sostok sostok sostok sostok sostok sostok sostok sostok\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    print(\"Review:\",seq2text(xTrain[i]))\n",
    "    print(\"Original summary:\",seq2summary(yTrain[i]))\n",
    "    print(\"Predicted summary:\",decode_sequence(xTrain[i].reshape(1,max_text_len))) \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C49BJdiGjlGM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Text-summarization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
